{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html> \n",
    "    <head>\n",
    "        <link rel=\"preconnect\" href=\"//fdn.fontcdn.ir\">\n",
    "        <link rel=\"preconnect\" href=\"//v1.fontapi.ir\">\n",
    "        <link href=\"https://v1.fontapi.ir/css/Vazir\" rel=\"stylesheet\">\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1 dir=\"rtl\" style=\"font-family: 'Vazir', sans-serif; line-height: 1.8;\"> بوستان و گلستان سعدی\n",
    "        </h1>\n",
    "        <p dir=\"rtl\" style=\"font-family: 'Vazir', sans-serif; line-height: 1.6;\">\n",
    "        در این پروژه موضوع بوستان و گلستان سعدی انتخاب شده است.\n",
    "          <br>\n",
    "         دیتای مورد نیاز برای این پروژه، کتاب بوستان و گلستان سعدی است که از سایت <a href=\"https://ganjoor.net//saadi/\">گنجور</a>\n",
    "          با استفاده از کرالری که نوشتیم و در فایل تمرین است، جمع‌آوری شده است.\n",
    "        <br>\n",
    "        هر حکایت یا شعر از این دو کتاب، در یک فایل .txt ذخیره شده است و در این قسمت داده ها از فایل‌های ذخیره شده، خوانده میشوند.\n",
    "            \n",
    "            \n",
    "<!--        </h3>\n",
    "    </body> -->\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html> \n",
    "    <head>\n",
    "        <link rel=\"preconnect\" href=\"//fdn.fontcdn.ir\">\n",
    "        <link rel=\"preconnect\" href=\"//v1.fontapi.ir\">\n",
    "        <link href=\"https://v1.fontapi.ir/css/Vazir\" rel=\"stylesheet\">\n",
    "    </head>\n",
    "    <body>\n",
    "     <p dir=\"rtl\" style=\"font-family: 'Vazir', sans-serif; line-height: 1.6;\">\n",
    "    ابتدا باید پکیج های مورد نیاز را نصب کنیم.\n",
    "</html>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install hazm\n",
    "!pip install future\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import codecs\n",
    "import tqdm\n",
    "import re\n",
    "import codecs\n",
    "import numpy as np\n",
    "from __future__ import unicode_literals\n",
    "import random\n",
    "import os, os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get number of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boostanPath = \"./Boostan\"\n",
    "golestanPath = \"./Golestan\"\n",
    "NumOfBoostanFiles = len([name for name in os.listdir(boostanPath)])\n",
    "NumOfGolestanFiles = len([name for name in os.listdir(golestanPath)])\n",
    "NumOfBoostanFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html> \n",
    "    <head>\n",
    "        <link rel=\"preconnect\" href=\"//fdn.fontcdn.ir\">\n",
    "        <link rel=\"preconnect\" href=\"//v1.fontapi.ir\">\n",
    "        <link href=\"https://v1.fontapi.ir/css/Vazir\" rel=\"stylesheet\">\n",
    "    </head>\n",
    "    <body>\n",
    "     <p dir=\"rtl\" style=\"font-family: 'Vazir', sans-serif; line-height: 1.6;\">\n",
    "        نام فایل های بوستان و گلستان سعدی را در دو آرایه ذخیره میکنیم تا بعدا از آنها استفاده کنیم.\n",
    "\n",
    "</html> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html> \n",
    "    <head>\n",
    "        <link rel=\"preconnect\" href=\"//fdn.fontcdn.ir\">\n",
    "        <link rel=\"preconnect\" href=\"//v1.fontapi.ir\">\n",
    "        <link href=\"https://v1.fontapi.ir/css/Vazir\" rel=\"stylesheet\">\n",
    "    </head>\n",
    "    <body>\n",
    "     <p dir=\"rtl\" style=\"font-family: 'Vazir', sans-serif; line-height: 1.6;\">\n",
    "        فایل های بوستان\n",
    "</html> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\university\\14002\\MIR\\MIR-Saadi\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\uXXXX escape (<ipython-input-9-139deb320623>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-139deb320623>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    boostan_folder_path = \"e:\\university/14002\\MIR\"\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\uXXXX escape\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd()) \n",
    "boostan_folder_path = \".\"\n",
    "\n",
    "\n",
    "boostan_file_name = []\n",
    "golestan_file_name = []\n",
    "\n",
    "os.chdir(boostan_folder_path)\n",
    "for filename in os.listdir(boostan_folder_path):\n",
    "    if os.path.isfile(filename):\n",
    "        boostan_file_name.append(filename)\n",
    "\n",
    "# os.chdir(\"..\")\n",
    "print(os.getcwd()) \n",
    "boostan_file_name[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html> \n",
    "    <head>\n",
    "        <link rel=\"preconnect\" href=\"//fdn.fontcdn.ir\">\n",
    "        <link rel=\"preconnect\" href=\"//v1.fontapi.ir\">\n",
    "        <link href=\"https://v1.fontapi.ir/css/Vazir\" rel=\"stylesheet\">\n",
    "    </head>\n",
    "    <body>\n",
    "     <p dir=\"rtl\" style=\"font-family: 'Vazir', sans-serif; line-height: 1.6;\">\n",
    "        فایل های گلستان\n",
    "</html> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\university\\14002\\MIR\\MIR-Saadi\n",
      "291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dibache.txt',\n",
       " 'gbab1sh1.txt',\n",
       " 'gbab1sh10.txt',\n",
       " 'gbab1sh11.txt',\n",
       " 'gbab1sh12.txt',\n",
       " 'gbab1sh13.txt',\n",
       " 'gbab1sh14.txt',\n",
       " 'gbab1sh15.txt',\n",
       " 'gbab1sh16.txt',\n",
       " 'gbab1sh17.txt',\n",
       " 'gbab1sh18.txt',\n",
       " 'gbab1sh19.txt',\n",
       " 'gbab1sh2.txt',\n",
       " 'gbab1sh20.txt',\n",
       " 'gbab1sh21.txt',\n",
       " 'gbab1sh22.txt',\n",
       " 'gbab1sh23.txt',\n",
       " 'gbab1sh24.txt',\n",
       " 'gbab1sh25.txt',\n",
       " 'gbab1sh26.txt',\n",
       " 'gbab1sh27.txt',\n",
       " 'gbab1sh28.txt',\n",
       " 'gbab1sh29.txt',\n",
       " 'gbab1sh3.txt',\n",
       " 'gbab1sh30.txt',\n",
       " 'gbab1sh31.txt',\n",
       " 'gbab1sh32.txt',\n",
       " 'gbab1sh33.txt',\n",
       " 'gbab1sh34.txt',\n",
       " 'gbab1sh35.txt',\n",
       " 'gbab1sh36.txt',\n",
       " 'gbab1sh37.txt',\n",
       " 'gbab1sh38.txt',\n",
       " 'gbab1sh39.txt',\n",
       " 'gbab1sh4.txt',\n",
       " 'gbab1sh40.txt',\n",
       " 'gbab1sh41.txt',\n",
       " 'gbab1sh5.txt',\n",
       " 'gbab1sh6.txt',\n",
       " 'gbab1sh7.txt',\n",
       " 'gbab1sh8.txt',\n",
       " 'gbab1sh9.txt',\n",
       " 'gbab2sh1.txt',\n",
       " 'gbab2sh10.txt',\n",
       " 'gbab2sh11.txt',\n",
       " 'gbab2sh12.txt',\n",
       " 'gbab2sh13.txt',\n",
       " 'gbab2sh14.txt',\n",
       " 'gbab2sh15.txt',\n",
       " 'gbab2sh16.txt',\n",
       " 'gbab2sh17.txt',\n",
       " 'gbab2sh18.txt',\n",
       " 'gbab2sh19.txt',\n",
       " 'gbab2sh2.txt',\n",
       " 'gbab2sh20.txt',\n",
       " 'gbab2sh21.txt',\n",
       " 'gbab2sh22.txt',\n",
       " 'gbab2sh23.txt',\n",
       " 'gbab2sh24.txt',\n",
       " 'gbab2sh25.txt',\n",
       " 'gbab2sh26.txt',\n",
       " 'gbab2sh27.txt',\n",
       " 'gbab2sh28.txt',\n",
       " 'gbab2sh29.txt',\n",
       " 'gbab2sh3.txt',\n",
       " 'gbab2sh30.txt',\n",
       " 'gbab2sh31.txt',\n",
       " 'gbab2sh32.txt',\n",
       " 'gbab2sh33.txt',\n",
       " 'gbab2sh34.txt',\n",
       " 'gbab2sh35.txt',\n",
       " 'gbab2sh36.txt',\n",
       " 'gbab2sh37.txt',\n",
       " 'gbab2sh38.txt',\n",
       " 'gbab2sh39.txt',\n",
       " 'gbab2sh4.txt',\n",
       " 'gbab2sh40.txt',\n",
       " 'gbab2sh41.txt',\n",
       " 'gbab2sh42.txt',\n",
       " 'gbab2sh43.txt',\n",
       " 'gbab2sh44.txt',\n",
       " 'gbab2sh45.txt',\n",
       " 'gbab2sh46.txt',\n",
       " 'gbab2sh47.txt',\n",
       " 'gbab2sh48.txt',\n",
       " 'gbab2sh5.txt',\n",
       " 'gbab2sh6.txt',\n",
       " 'gbab2sh7.txt',\n",
       " 'gbab2sh8.txt',\n",
       " 'gbab2sh9.txt',\n",
       " 'gbab3sh1.txt',\n",
       " 'gbab3sh10.txt',\n",
       " 'gbab3sh11.txt',\n",
       " 'gbab3sh12.txt',\n",
       " 'gbab3sh13.txt',\n",
       " 'gbab3sh14.txt',\n",
       " 'gbab3sh15.txt',\n",
       " 'gbab3sh16.txt',\n",
       " 'gbab3sh17.txt',\n",
       " 'gbab3sh18.txt',\n",
       " 'gbab3sh19.txt',\n",
       " 'gbab3sh2.txt',\n",
       " 'gbab3sh20.txt',\n",
       " 'gbab3sh21.txt',\n",
       " 'gbab3sh22.txt',\n",
       " 'gbab3sh23.txt',\n",
       " 'gbab3sh24.txt',\n",
       " 'gbab3sh25.txt',\n",
       " 'gbab3sh26.txt',\n",
       " 'gbab3sh27.txt',\n",
       " 'gbab3sh28.txt',\n",
       " 'gbab3sh3.txt',\n",
       " 'gbab3sh4.txt',\n",
       " 'gbab3sh5.txt',\n",
       " 'gbab3sh6.txt',\n",
       " 'gbab3sh7.txt',\n",
       " 'gbab3sh8.txt',\n",
       " 'gbab3sh9.txt',\n",
       " 'gbab4sh1.txt',\n",
       " 'gbab4sh10.txt',\n",
       " 'gbab4sh11.txt',\n",
       " 'gbab4sh12.txt',\n",
       " 'gbab4sh13.txt',\n",
       " 'gbab4sh14.txt',\n",
       " 'gbab4sh2.txt',\n",
       " 'gbab4sh3.txt',\n",
       " 'gbab4sh4.txt',\n",
       " 'gbab4sh5.txt',\n",
       " 'gbab4sh6.txt',\n",
       " 'gbab4sh7.txt',\n",
       " 'gbab4sh8.txt',\n",
       " 'gbab4sh9.txt',\n",
       " 'gbab5sh1.txt',\n",
       " 'gbab5sh10.txt',\n",
       " 'gbab5sh11.txt',\n",
       " 'gbab5sh12.txt',\n",
       " 'gbab5sh13.txt',\n",
       " 'gbab5sh14.txt',\n",
       " 'gbab5sh15.txt',\n",
       " 'gbab5sh16.txt',\n",
       " 'gbab5sh17.txt',\n",
       " 'gbab5sh18.txt',\n",
       " 'gbab5sh19.txt',\n",
       " 'gbab5sh2.txt',\n",
       " 'gbab5sh20.txt',\n",
       " 'gbab5sh21.txt',\n",
       " 'gbab5sh3.txt',\n",
       " 'gbab5sh4.txt',\n",
       " 'gbab5sh5.txt',\n",
       " 'gbab5sh6.txt',\n",
       " 'gbab5sh7.txt',\n",
       " 'gbab5sh8.txt',\n",
       " 'gbab5sh9.txt',\n",
       " 'gbab6sh1.txt',\n",
       " 'gbab6sh2.txt',\n",
       " 'gbab6sh3.txt',\n",
       " 'gbab6sh4.txt',\n",
       " 'gbab6sh5.txt',\n",
       " 'gbab6sh6.txt',\n",
       " 'gbab6sh7.txt',\n",
       " 'gbab6sh8.txt',\n",
       " 'gbab6sh9.txt',\n",
       " 'gbab7sh1.txt',\n",
       " 'gbab7sh10.txt',\n",
       " 'gbab7sh11.txt',\n",
       " 'gbab7sh12.txt',\n",
       " 'gbab7sh13.txt',\n",
       " 'gbab7sh14.txt',\n",
       " 'gbab7sh15.txt',\n",
       " 'gbab7sh16.txt',\n",
       " 'gbab7sh17.txt',\n",
       " 'gbab7sh18.txt',\n",
       " 'gbab7sh19.txt',\n",
       " 'gbab7sh2.txt',\n",
       " 'gbab7sh20.txt',\n",
       " 'gbab7sh3.txt',\n",
       " 'gbab7sh4.txt',\n",
       " 'gbab7sh5.txt',\n",
       " 'gbab7sh6.txt',\n",
       " 'gbab7sh7.txt',\n",
       " 'gbab7sh8.txt',\n",
       " 'gbab7sh9.txt',\n",
       " 'gbab8sh1.txt',\n",
       " 'gbab8sh10.txt',\n",
       " 'gbab8sh100.txt',\n",
       " 'gbab8sh101.txt',\n",
       " 'gbab8sh102.txt',\n",
       " 'gbab8sh103.txt',\n",
       " 'gbab8sh104.txt',\n",
       " 'gbab8sh105.txt',\n",
       " 'gbab8sh106.txt',\n",
       " 'gbab8sh107.txt',\n",
       " 'gbab8sh108.txt',\n",
       " 'gbab8sh109.txt',\n",
       " 'gbab8sh11.txt',\n",
       " 'gbab8sh12.txt',\n",
       " 'gbab8sh13.txt',\n",
       " 'gbab8sh14.txt',\n",
       " 'gbab8sh15.txt',\n",
       " 'gbab8sh16.txt',\n",
       " 'gbab8sh17.txt',\n",
       " 'gbab8sh18.txt',\n",
       " 'gbab8sh19.txt',\n",
       " 'gbab8sh2.txt',\n",
       " 'gbab8sh20.txt',\n",
       " 'gbab8sh21.txt',\n",
       " 'gbab8sh22.txt',\n",
       " 'gbab8sh23.txt',\n",
       " 'gbab8sh24.txt',\n",
       " 'gbab8sh25.txt',\n",
       " 'gbab8sh26.txt',\n",
       " 'gbab8sh27.txt',\n",
       " 'gbab8sh28.txt',\n",
       " 'gbab8sh29.txt',\n",
       " 'gbab8sh3.txt',\n",
       " 'gbab8sh30.txt',\n",
       " 'gbab8sh31.txt',\n",
       " 'gbab8sh32.txt',\n",
       " 'gbab8sh33.txt',\n",
       " 'gbab8sh34.txt',\n",
       " 'gbab8sh35.txt',\n",
       " 'gbab8sh36.txt',\n",
       " 'gbab8sh37.txt',\n",
       " 'gbab8sh38.txt',\n",
       " 'gbab8sh39.txt',\n",
       " 'gbab8sh4.txt',\n",
       " 'gbab8sh40.txt',\n",
       " 'gbab8sh41.txt',\n",
       " 'gbab8sh42.txt',\n",
       " 'gbab8sh43.txt',\n",
       " 'gbab8sh44.txt',\n",
       " 'gbab8sh45.txt',\n",
       " 'gbab8sh46.txt',\n",
       " 'gbab8sh47.txt',\n",
       " 'gbab8sh48.txt',\n",
       " 'gbab8sh49.txt',\n",
       " 'gbab8sh5.txt',\n",
       " 'gbab8sh50.txt',\n",
       " 'gbab8sh51.txt',\n",
       " 'gbab8sh52.txt',\n",
       " 'gbab8sh53.txt',\n",
       " 'gbab8sh54.txt',\n",
       " 'gbab8sh55.txt',\n",
       " 'gbab8sh56.txt',\n",
       " 'gbab8sh57.txt',\n",
       " 'gbab8sh58.txt',\n",
       " 'gbab8sh59.txt',\n",
       " 'gbab8sh6.txt',\n",
       " 'gbab8sh60.txt',\n",
       " 'gbab8sh61.txt',\n",
       " 'gbab8sh62.txt',\n",
       " 'gbab8sh63.txt',\n",
       " 'gbab8sh64.txt',\n",
       " 'gbab8sh65.txt',\n",
       " 'gbab8sh66.txt',\n",
       " 'gbab8sh67.txt',\n",
       " 'gbab8sh68.txt',\n",
       " 'gbab8sh69.txt',\n",
       " 'gbab8sh7.txt',\n",
       " 'gbab8sh70.txt',\n",
       " 'gbab8sh71.txt',\n",
       " 'gbab8sh72.txt',\n",
       " 'gbab8sh73.txt',\n",
       " 'gbab8sh74.txt',\n",
       " 'gbab8sh75.txt',\n",
       " 'gbab8sh76.txt',\n",
       " 'gbab8sh77.txt',\n",
       " 'gbab8sh78.txt',\n",
       " 'gbab8sh79.txt',\n",
       " 'gbab8sh8.txt',\n",
       " 'gbab8sh80.txt',\n",
       " 'gbab8sh81.txt',\n",
       " 'gbab8sh82.txt',\n",
       " 'gbab8sh83.txt',\n",
       " 'gbab8sh84.txt',\n",
       " 'gbab8sh85.txt',\n",
       " 'gbab8sh86.txt',\n",
       " 'gbab8sh87.txt',\n",
       " 'gbab8sh88.txt',\n",
       " 'gbab8sh89.txt',\n",
       " 'gbab8sh9.txt',\n",
       " 'gbab8sh90.txt',\n",
       " 'gbab8sh91.txt',\n",
       " 'gbab8sh92.txt',\n",
       " 'gbab8sh93.txt',\n",
       " 'gbab8sh94.txt',\n",
       " 'gbab8sh95.txt',\n",
       " 'gbab8sh96.txt',\n",
       " 'gbab8sh97.txt',\n",
       " 'gbab8sh98.txt',\n",
       " 'gbab8sh99.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.getcwd())  \n",
    "golestan_folder_path = \"./Golestan\"\n",
    "os.chdir(golestan_folder_path)\n",
    "print(len(os.listdir()))\n",
    "for filename in os.listdir():\n",
    "    if os.path.isfile(filename):\n",
    "        golestan_file_name.append(filename)\n",
    "os.chdir(\"..\")\n",
    "golestan_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make array for golestan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'golestan_file_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4cab51d1fdc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgolestan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgolestan_file_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./Golestan/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'golestan_file_name' is not defined"
     ]
    }
   ],
   "source": [
    "golestan = ''\n",
    "\n",
    "for file in golestan_file_name:\n",
    "    f = open(\"./Golestan/\"+file, \"r\", encoding=\"utf-8\")\n",
    "    text = f.read()\n",
    "    golestan += text\n",
    "    golestan += \"\\n\"\n",
    "\n",
    "golestan_poems = golestan.split(\"\\n\")\n",
    "golestan_poems[0:10]\n",
    "golestan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make array for boostan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['بیا تا برآریم دستی ز دل',\n",
       " 'که نتوان برآورد فردا ز گل',\n",
       " 'به فصل خزان در نبینی درخت',\n",
       " 'که بی برگ ماند ز سرمای سخت',\n",
       " 'برآرد تهی دستهای نیاز',\n",
       " 'ز رحمت نگردد تهیدست باز',\n",
       " 'مپندار از آن در که هرگز نبست',\n",
       " 'که نومید گردد بر آورده دست',\n",
       " 'قضا خلعتی نامدارش دهد',\n",
       " 'قدر میوه در آستینش نهد']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boostan = ''\n",
    "\n",
    "for file in boostan_file_name:\n",
    "    fi = open(\"./Boostan/\"+file, \"r\", encoding=\"utf-8\")\n",
    "    text = fi.read()\n",
    "    boostan += text\n",
    "    boostan += \"\\n\"\n",
    "\n",
    "boostan_poems = boostan.split(\"\\n\")\n",
    "boostan_poems[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start preprocessing Boostan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize boostan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Normalizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d6dadc995620>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnormalizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNormalizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnormalized_boostan_poems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mboostan_poems\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnormalized_boostan_poems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnormalized_boostan_poems\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Normalizer' is not defined"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer()\n",
    "normalized_boostan_poems = []\n",
    "for p in boostan_poems:\n",
    "    normalized_boostan_poems.append(normalizer.normalize(p))\n",
    "normalized_boostan_poems[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lemmatize and remove stopwords boostan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['آمد#آ برآریم دست دل', 'توانست#توان برآورد فردا گل', 'فصل خزان دید#بین درخت', 'برگ ماند#مان سرما سخت', 'برآرد تهی دست', 'رحمت گشت#گرد تهیدست', 'مپندار هرگز بست#بند', 'نومید آورده دست', 'قضا خلعت نامدار', 'قدر میوه آستین نهد']\n",
      "[['آمد#آ', 'برآریم', 'دست', 'دل'], ['توانست#توان', 'برآورد', 'فردا', 'گل'], ['فصل', 'خزان', 'دید#بین', 'درخت'], ['برگ', 'ماند#مان', 'سرما', 'سخت'], ['برآرد', 'تهی', 'دست'], ['رحمت', 'گشت#گرد', 'تهیدست'], ['مپندار', 'هرگز', 'بست#بند'], ['نومید', 'آورده', 'دست'], ['قضا', 'خلعت', 'نامدار'], ['قدر', 'میوه', 'آستین', 'نهد']]\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = Lemmatizer()\n",
    "lemmatize_boostan_poems = []\n",
    "all_cleaned_tokens = []\n",
    "stopwords = [normalizer.normalize(x.strip()) for x in stopwords_list()]+[\"-\", \"/\", \"ز\", '\\ufeff', \"]\", \"[\", \"?\", \"؟\"]\n",
    "\n",
    "mesra_boostan = []\n",
    "mesra_boostan_tokenized = []\n",
    "\n",
    "for p in normalized_boostan_poems:\n",
    "    all_tokens =  word_tokenize(p)\n",
    "    all_tokens_nonstop = [t for t in (all_tokens) if t not in stopwords]\n",
    "    all_tokens_nonstop = [t for t in (all_tokens_nonstop) if len(t)>1]\n",
    "\n",
    "    all_tokens_lemm = []\n",
    "    for i in all_tokens_nonstop:\n",
    "        all_tokens_lemm.append(lemmatizer.lemmatize(i))\n",
    "    \n",
    "    mesra_boostan.append(' '.join(all_tokens_lemm))\n",
    "    # print(all_tokens_nonstop[0])\n",
    "    mesra_boostan_tokenized.append(all_tokens_lemm)\n",
    "\n",
    "print(mesra_boostan[0:10])\n",
    "print(mesra_boostan_tokenized[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start preprocessing Golestan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize golestan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['بسم الله الرحمن الرحیم',\n",
       " 'منت خدای را عز و جل که طاعتش موجب قربت است و به شکر اندرش مزید نعمت. هر نفسی که فرو می\\u200cرود ممد حیات است و چون بر می\\u200cآید مفرح ذات. پس در هر نفسی دو نعمت موجود است و بر هر نعمتی شکری واجب.',\n",
       " 'از دست و زبان که بر آید',\n",
       " 'کز عهدهٔ شکرش به در آید',\n",
       " 'اعملوا آل داود شکرا و قلیل من عبادی الشکور',\n",
       " 'بنده همان به که ز تقصیر خویش',\n",
       " 'عذر به درگاه خدای آورد',\n",
       " 'ور نه سزاوار خداوندیش',\n",
       " 'کس نتواند که به جای آورد',\n",
       " 'باران رحمت بی حسابش همه را رسیده و خوان نعمت بی دریغش همه جا کشیده. پردهٔ ناموس بندگان به گناه فاحش ندرد و وظیفهٔ روزی به خطای منکر نبرد.']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = Normalizer()\n",
    "normalized_golestan_poems = []\n",
    "for p in golestan_poems:\n",
    "    normalized_golestan_poems.append(normalizer.normalize(p))\n",
    "normalized_golestan_poems[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['بس الله الرحمن الرحیم', 'منت خدا عز جل طاعت قربت شکر اندر مزید نعمت نفس فرو ممد حیات مفرح ذات نفس نعمت موجود نعمت شکر واجب', 'دست زبان آمد#آ', 'کز عهده شکر آمد#آ', 'اعملوا آل داود شکرا قلیل عبادی الشکور', 'بنده تقصیر', 'عذر درگاه خدا', 'ور سزاوار خداوند', 'کس توانست#توان', 'باران رحمت حساب رسیده خوان نعمت دریغ کشیده پرده ناموس بندگان گناه فاحش ندرد وظیفه روز خطا منکر نبرد']\n",
      "[['بس', 'الله', 'الرحمن', 'الرحیم'], ['منت', 'خدا', 'عز', 'جل', 'طاعت', 'قربت', 'شکر', 'اندر', 'مزید', 'نعمت', 'نفس', 'فرو', 'ممد', 'حیات', 'مفرح', 'ذات', 'نفس', 'نعمت', 'موجود', 'نعمت', 'شکر', 'واجب'], ['دست', 'زبان', 'آمد#آ'], ['کز', 'عهده', 'شکر', 'آمد#آ'], ['اعملوا', 'آل', 'داود', 'شکرا', 'قلیل', 'عبادی', 'الشکور'], ['بنده', 'تقصیر'], ['عذر', 'درگاه', 'خدا'], ['ور', 'سزاوار', 'خداوند'], ['کس', 'توانست#توان'], ['باران', 'رحمت', 'حساب', 'رسیده', 'خوان', 'نعمت', 'دریغ', 'کشیده', 'پرده', 'ناموس', 'بندگان', 'گناه', 'فاحش', 'ندرد', 'وظیفه', 'روز', 'خطا', 'منکر', 'نبرد']]\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = Lemmatizer()\n",
    "lemmatize_golestan_poems = []\n",
    "all_cleaned_tokens = []\n",
    "stopwords = [normalizer.normalize(x.strip()) for x in stopwords_list()]+[\"-\", \"/\", \"ز\", '\\ufeff', \"]\", \"[\", \"?\", \"؟\"]\n",
    "\n",
    "mesra_golestan = []\n",
    "mesra_golestan_tokenized = []\n",
    "\n",
    "for p in normalized_golestan_poems:\n",
    "    all_tokens =  word_tokenize(p)\n",
    "    all_tokens_nonstop_g = [t for t in (all_tokens) if t not in stopwords]\n",
    "    all_tokens_nonstop_g = [t for t in (all_tokens_nonstop_g) if len(t)>1]\n",
    "\n",
    "    all_tokens_lemm = []\n",
    "    for i in all_tokens_nonstop_g:\n",
    "        all_tokens_lemm.append(lemmatizer.lemmatize(i))\n",
    "    \n",
    "    mesra_golestan.append(' '.join(all_tokens_lemm))\n",
    "    # print(all_tokens_nonstop[0])\n",
    "    mesra_golestan_tokenized.append(all_tokens_lemm)\n",
    "\n",
    "print(mesra_golestan[0:10])\n",
    "print(mesra_golestan_tokenized[0:10])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
