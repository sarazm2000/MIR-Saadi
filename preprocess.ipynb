{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install hazm\n",
    "!pip install future\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import codecs\n",
    "import tqdm\n",
    "import re\n",
    "import codecs\n",
    "import numpy as np\n",
    "from __future__ import unicode_literals\n",
    "import random\n",
    "import os, os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get number of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boostanPath = \"./Boostan\"\n",
    "golestanPath = \"./Golestan\"\n",
    "NumOfBoostanFiles = len([name for name in os.listdir(boostanPath)])\n",
    "NumOfGolestanFiles = len([name for name in os.listdir(golestanPath)])\n",
    "NumOfBoostanFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../boostan\"\n",
    "os.chdir(folder_path)\n",
    "\n",
    "boostan_file_name = []\n",
    "golestan_file_name = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    f = os.path.join(folder_path, filename)\n",
    "    if os.path.isfile(f):\n",
    "        boostan_file_name.append(f)\n",
    "        \n",
    "folder_path = \"../golestan\"\n",
    "os.chdir(folder_path)\n",
    "print(len(os.listdir()))\n",
    "for filename in os.listdir():\n",
    "    f = os.path.join(folder_path, filename)\n",
    "    if os.path.isfile(f):\n",
    "        golestan_file_name.append(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boostan_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make array for golestan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golestan = ''\n",
    "\n",
    "for file in golestan_file_name:\n",
    "    f = open(file, \"r\", encoding=\"utf-8\")\n",
    "    text = f.read()\n",
    "    golestan += text\n",
    "    golestan += \"\\n\"\n",
    "\n",
    "golestan_poems = golestan.split(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make array for boostan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boostan = ''\n",
    "\n",
    "for file in boostan_file_name:\n",
    "    fi = open(file, \"r\", encoding=\"utf-8\")\n",
    "    text = fi.read()\n",
    "    boostan += text\n",
    "    boostan += \"\\n\"\n",
    "\n",
    "boostan_poems = boostan.split(\"\\n\")\n",
    "boostan_poems[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize boostan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "normalized_boostan_poems = []\n",
    "for p in boostan_poems:\n",
    "    normalized_boostan_poems.append(normalizer.normalize(p))\n",
    "# normalized_boostan_poems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lemmatize boostan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = Lemmatizer()\n",
    "lemmatize_boostan_poems = []\n",
    "for p in normalized_boostan_poems:\n",
    "    lemmatize_boostan_poems.append(lemmatizer.lemmatize(p))\n",
    "lemmatize_boostan_poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_boostan = []\n",
    "for a in normalized_boostan_poems: \n",
    "    all_tokens_boostan.append(word_tokenize(a))\n",
    "\n",
    "all_tokens_boostan_lemmatized = []\n",
    "for i in all_tokens_boostan:\n",
    "    for t in i:\n",
    "        all_tokens_boostan_lemmatized.append(lemmatizer.lemmatize(t))\n",
    "\n",
    "all_tokens_boostan_lemmatized[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove stopwords from boostan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_nonstop_boostan = [t for t in tqdm.tqdm(all_tokens_boostan_lemmatized) if t not in stopwords_list()]\n",
    "all_token_nonstop_boostan[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "golestan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalized golestan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "normalized_golestan_poems = []\n",
    "for p in golestan_poems:\n",
    "    normalized_golestan_poems.append(normalizer.normalize(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = Lemmatizer()\n",
    "lemmatize_golestan_poems = []\n",
    "for p in normalized_golestan_poems:\n",
    "    lemmatize_golestan_poems.append(lemmatizer.lemmatize(p))\n",
    "lemmatize_golestan_poems[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize golestan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['نعمت', '.', 'هر', 'نفس', 'که', 'فرو', 'رفت#رو', 'ممد', 'حیات', '#است']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_golestan = []\n",
    "for a in normalized_golestan_poems: \n",
    "    all_tokens_golestan.append(word_tokenize(a))\n",
    "\n",
    "all_tokens_golestan_lemmatized = []\n",
    "for i in all_tokens_golestan:\n",
    "    for t in i:\n",
    "        all_tokens_golestan_lemmatized.append(lemmatizer.lemmatize(t))\n",
    "\n",
    "all_tokens_golestan_lemmatized[20:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove stopwords from golestan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39939/39939 [00:40<00:00, 995.09it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['بس', 'الله', 'الرحمن', 'الرحیم', 'منت', 'خدا', 'عز', 'جل', 'طاعت', 'قربت']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_token_nonstop_golestan = [t for t in tqdm.tqdm(all_tokens_golestan_lemmatized) if t not in stopwords_list()]\n",
    "all_token_nonstop_golestan[0:10]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
